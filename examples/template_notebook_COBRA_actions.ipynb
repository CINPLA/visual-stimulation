{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# register and preprocess\n",
    "Run from here (as `!expipe register etc.`) or terminal (without exclamation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "!expipe register openephys /Users/ehagen/COBRA/COBRA_exp_data/1010_2018-10-29_18-02-16_1/ --user Espen --location expipehell --overwrite\n",
    "!expipe register process --probe-path /Users/ehagen/COBRA/COBRA_exp_data/neuronexus-32-linear-list.prb --sorter ironclust 1010-291018-1\n",
    "!expipe register psychopy 1010-291018-1\n",
    "!expipe register mousexy  1010-291018-1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import expipe\n",
    "import os\n",
    "from expipe_plugin_cinpla.imports import project\n",
    "import quantities as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "import h5py\n",
    "import neo\n",
    "import exdir\n",
    "import exdir.plugins.git_lfs # stupid\n",
    "#from exana.statistics import correlogram\n",
    "import pandas\n",
    "import scipy.signal as ss\n",
    "import elephant.current_source_density as csd\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams.update(**plt.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "    #'figure.dpi' : 150,\n",
    "    'figure.figsize' : [6.4*1.5, 4.8*1.5],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expipe.config.settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action_id = '1006-121018-03'\n",
    "#action_id = '1011-301018-1'\n",
    "#action_id = '1012-090119-01' # flashes_quick\n",
    "#action_id = '1012-090119-02' # gratings_quick\n",
    "#action_id = '1012-090119-04' # flashes_quick\n",
    "#action_id = '1012-090119-05' # gratings_quick\n",
    "action_id = '1012-090119-06' # gratings\n",
    "#action_id = '1012-090119-07' # images\n",
    "#action_id = '1012-090119-08' # sparsenoise\n",
    "#action_id = '1012-090119-09'  # static gratings\n",
    "#action_id = '1012-090119-10' # videos\n",
    "#action_id = '1012-090119-11' # flashes_quick\n",
    "#action_id = '1012-090119-11' # gratings_quick\n",
    "#project_id = PAR.PROJECT_ID\n",
    "#project = PAR.PROJECT\n",
    "action = project.actions[action_id]\n",
    "from expipe_plugin_cinpla.scripts.utils import _get_data_path\n",
    "exdir_path = _get_data_path(action)\n",
    "#exdir_path = os.path.join(str(action._backend.path), 'data', 'main.exdir')\n",
    "channel_group = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = ANALYSIS_PARAMS = {\n",
    "    'speed_filter': 5 * pq.m / pq.s,\n",
    "    'pos_fs': 100 * pq.Hz,\n",
    "    'f_cut': 6 * pq.Hz,\n",
    "    'spat_binsize': 0.02 * pq.m,\n",
    "    'spat_smoothing': 0.025,\n",
    "    'grid_stepsize': 0.1 * pq.m,\n",
    "    'box_xlen': 1 * pq.m,\n",
    "    'box_ylen': 1 * pq.m,\n",
    "    'ang_binsize': 4,\n",
    "    'ang_n_avg_bin': 4,\n",
    "    'imgformat': '.png',\n",
    "    'corr_bin_width': 0.001 * pq.s,\n",
    "    'corr_limit': 0.1 * pq.s,\n",
    "    'isi_binsize': 1 * pq.ms,\n",
    "    'isi_time_limit': 100 * pq.ms,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier params\n",
    "NFFT = 512\n",
    "noverlap = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stimulus epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = exdir.File(exdir_path, 'r', plugins=[exdir.plugins.quantities, exdir.plugins.git_lfs])\n",
    "stim = f['processing']['epochs']['visual_stimulus']\n",
    "grp = stim[list(stim.keys())[0]]\n",
    "if list(stim.keys()) == ['image']:\n",
    "    stimulation_type = 'image'\n",
    "    # nicer label formatting\n",
    "    labels = np.array([pathlib.PureWindowsPath(lbl).parts[-1].rstrip('.png') for lbl in grp['image'].value])\n",
    "    epo=neo.Epoch(times=grp['times'].value, \n",
    "                  durations=grp['duration'].value*pq.s, \n",
    "                  labels=labels)\n",
    "elif list(stim.keys()) == ['grating']:\n",
    "    stimulation_type = 'grating'\n",
    "    annotations = dict(frequency=grp['frequency'].value*pq.Hz,\n",
    "                       orientation=grp['orientation'].value*pq.deg,\n",
    "                       phase=grp['phase'].value,\n",
    "                       spatial_frequency=grp['spatial_frequency'].value\n",
    "                      )\n",
    "    df = pandas.DataFrame(annotations)\n",
    "    # nicer label formatting\n",
    "    labels = np.array([df.loc[i].to_csv().replace(',', ':').replace('\\n', ',') for i in range(df.shape[0])])\n",
    "    labels = [label.replace('spatial_frequency:', '\\omega=') for label in labels]\n",
    "    labels = [label.replace('frequency:', 'f=') for label in labels]\n",
    "    labels = [label.replace('orientation:', r'\\alpha=') for label in labels]\n",
    "    labels = [label.replace('phase:', r'\\theta=') for label in labels]\n",
    "    labels = np.array([r'${}$'.format(label) for label in labels])\n",
    "    epo=neo.Epoch(times=grp['times'].value, \n",
    "                  durations=grp['duration'].value*pq.s, \n",
    "                  labels=labels,\n",
    "                  **annotations)\n",
    "elif list(stim.keys()) == ['sparsenoise']:\n",
    "    stimulation_type = 'sparsenoise'\n",
    "    epo=neo.Epoch(times=grp['times'].value, \n",
    "                  durations=grp['duration'].value*pq.s, \n",
    "                  labels=grp['image'].value)\n",
    "elif list(stim.keys()) == ['movie']:\n",
    "    stimulation_type = 'movie'\n",
    "    # nicer label formatting\n",
    "    labels = np.array([pathlib.PureWindowsPath(lbl).parts[-1].rstrip('.mp4') for lbl in grp['movie'].value])\n",
    "    epo=neo.Epoch(times=grp['times'].value, \n",
    "                  durations=np.array([30.]*grp['times'].size)*pq.s, #### HACK!!!! ###### \n",
    "                  labels=labels)\n",
    "elif list(stim.keys()) == ['flash']:\n",
    "    stimulation_type = 'flash'\n",
    "    epo=neo.Epoch(times=grp['times'].value, \n",
    "                  durations=(grp['duration'].value + 0.25)*pq.s, \n",
    "                  labels=grp['color'].value)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulation_type , epo.times, epo.durations #, seg.analogsignals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spikes\n",
    "Load all spiketrains as list of `neo.SpikeTrain` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_waveforms = True\n",
    "if load_waveforms:\n",
    "    f = exdir.File(exdir_path, 'r', plugins=[exdir.plugins.quantities, exdir.plugins.git_lfs])\n",
    "    io = neo.ExdirIO(str(exdir_path))\n",
    "    blk = io.read_block()\n",
    "    blk_cluster_ids = np.array([str(unit.annotations['cluster_id']) for unit in blk.channel_indexes[0].units])\n",
    "    t_stop = f.attrs['session_duration']\n",
    "    UnitTimes = f['processing']['electrophysiology']['channel_group_0']['UnitTimes']\n",
    "    units = np.sort(list(UnitTimes.keys()))\n",
    "    spiketrains = []\n",
    "    for unit in units:\n",
    "        if not UnitTimes[unit].attrs['cluster_group'] == 'noise':\n",
    "            spiketrains += [neo.SpikeTrain(UnitTimes[unit]['times'].value, t_stop=t_stop, \n",
    "                                          name=unit, description=UnitTimes[unit].attrs['cluster_group'],\n",
    "                                          waveforms=blk.segments[0].spiketrains[np.where(blk_cluster_ids==unit)[0][0]].waveforms)]\n",
    "    f.close()\n",
    "else:\n",
    "    f = exdir.File(exdir_path, 'r', plugins=[exdir.plugins.quantities, exdir.plugins.git_lfs])\n",
    "    t_stop = f.attrs['session_duration']\n",
    "    UnitTimes = f['processing']['electrophysiology']['channel_group_0']['UnitTimes']\n",
    "    units = np.sort(list(UnitTimes.keys()))\n",
    "    spiketrains = [neo.SpikeTrain(UnitTimes[unit]['times'].value, t_stop=t_stop, \n",
    "                                  name=unit, description=UnitTimes[unit].attrs['cluster_group'],\n",
    "                                  waveforms=None) \n",
    "                   for unit in units if not UnitTimes[unit].attrs['cluster_group'] == 'noise']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def some plotting functions\n",
    "def remove_axis_junk(ax, lines=['right', 'top']):\n",
    "    for loc, spine in ax.spines.items():\n",
    "        if loc in lines:\n",
    "            spine.set_color('none')            \n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "def draw_lineplot(\n",
    "        ax, data, dt=0.1,\n",
    "        T=(0, 200),\n",
    "        scaling_factor=1.,\n",
    "        vlimround=None,\n",
    "        label='local',\n",
    "        scalebar=True,\n",
    "        unit='mV',\n",
    "        ylabels=True,\n",
    "        color='k',\n",
    "        ztransform=True,\n",
    "        filter=False,\n",
    "        filterargs=dict(N=2, Wn=0.02, btype='lowpass')\n",
    "        ):\n",
    "    ''' draw some nice lines'''\n",
    "    \n",
    "    tvec = np.arange(data.shape[1])*dt\n",
    "    if T[0] < 0:\n",
    "        tvec += T[0]\n",
    "    try:\n",
    "        tinds = (tvec >= T[0]) & (tvec <= T[1])\n",
    "    except TypeError:\n",
    "        print(data.shape, T)\n",
    "        raise Exception\n",
    "    \n",
    "    # apply temporal filter\n",
    "    if filter:\n",
    "        b, a = ss.butter(**filterargs)\n",
    "        data = ss.filtfilt(b, a, data, axis=-1)\n",
    "    \n",
    "    #subtract mean in each channel\n",
    "    if ztransform:\n",
    "        dataT = data.T - data.mean(axis=1)\n",
    "        data = dataT.T\n",
    "\n",
    "    zvec = np.arange(data.shape[0])\n",
    "    vlim = abs(data[:, tinds]).max()\n",
    "    if vlimround is None:\n",
    "        vlimround = 2.**np.round(np.log2(vlim)) / scaling_factor\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    yticklabels=[]\n",
    "    yticks = []\n",
    "    \n",
    "    for i, z in enumerate(zvec):\n",
    "        if i == 0:\n",
    "            ax.plot(tvec[tinds], data[i][tinds] / vlimround + z, lw=.5,\n",
    "                    rasterized=False, label=label, clip_on=False,\n",
    "                    color=color)\n",
    "        else: \n",
    "            ax.plot(tvec[tinds], data[i][tinds] / vlimround + z, lw=.5,\n",
    "                    rasterized=False, clip_on=False,\n",
    "                    color=color)\n",
    "        yticklabels.append('ch. %i' % (i+1))\n",
    "        yticks.append(z)\n",
    "        \n",
    "    if scalebar:\n",
    "        ax.plot([tvec[tinds][-1], tvec[tinds][-1]],\n",
    "                [zvec[-1], zvec[-2]], lw=2, color='k', clip_on=False)\n",
    "        ax.text(tvec[tinds][-1]+np.diff(T)*0.0, np.mean([zvec[-1], zvec[-2]]),\n",
    "                '$2^{' + '{}'.format(int(np.log2(vlimround))) + '}$ ' + '{0}'.format(unit),\n",
    "                color='r', rotation='vertical',\n",
    "                va='center', zorder=100)\n",
    "\n",
    "    ax.axis(ax.axis('tight'))\n",
    "    if ylabels:\n",
    "        ax.yaxis.set_ticks(yticks)\n",
    "        ax.yaxis.set_ticklabels(yticklabels)\n",
    "        #ax.set_ylabel('channel', labelpad=0.1)\n",
    "    else:\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "    remove_axis_junk(ax, lines=['right', 'top'])\n",
    "    ax.set_xlabel(r't (ms)', labelpad=0.1)\n",
    "    \n",
    "    return vlimround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_waveforms:\n",
    "    vlimround=2**6\n",
    "    fig, axes = plt.subplots(1, len(spiketrains), sharey=True)\n",
    "    for i, (ax, spiketrain) in enumerate(zip(axes, spiketrains)):\n",
    "        mean = spiketrain.waveforms.mean(axis=0)\n",
    "        std = spiketrain.waveforms.std(axis=0)\n",
    "        draw_lineplot(ax, mean, dt=1./30, T=(-0.5, 1.5), vlimround=vlimround, unit=mean.dimensionality)\n",
    "        draw_lineplot(ax, mean+std*2, dt=1./30, T=(-.5, 1.5), vlimround=vlimround, scalebar=False, color='0.5')\n",
    "        draw_lineplot(ax, mean-std*2, dt=1./30, T=(-.5, 1.5), vlimround=vlimround, scalebar=False, color='0.5')\n",
    "        ax.set_title('#{}'.format(spiketrain.name))\n",
    "        if i != 0:\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFP, MUA and CSD\n",
    "LFPs, MUAs and corresponding reconstructed CSDs defined as `neo.AnalogSignal` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = exdir.File(exdir_path, 'r', plugins=[exdir.plugins.quantities])\n",
    "# LFP\n",
    "_lfp = f['processing']['electrophysiology']['channel_group_0']['LFP']\n",
    "keys = list(_lfp.keys())\n",
    "electrode_value = [_lfp[key]['data'].value.flatten() for key in keys]\n",
    "electrode_idx = [_lfp[key].attrs['electrode_idx'] for key in keys]\n",
    "sampling_rate = _lfp[keys[0]].attrs['sample_rate']\n",
    "units = _lfp[keys[0]]['data'].attrs['unit']\n",
    "LFP = np.r_[[_lfp[key]['data'].value.flatten() for key in keys]].T\n",
    "#LFP = (LFP.T - np.median(np.array(LFP), axis=-1)).T #CMR reference\n",
    "#LFP = (LFP.T - LFP[:, 0]).T # use topmost channel as reference\n",
    "LFP = LFP[:, np.argsort(electrode_idx)]\n",
    "\n",
    "LFP = neo.AnalogSignal(LFP, \n",
    "                       units=units, t_stop=t_stop, sampling_rate=sampling_rate)\n",
    "LFP = LFP.rescale('mV')\n",
    "\n",
    "# MUA\n",
    "_mua = f['processing']['electrophysiology']['channel_group_0']['MUA']\n",
    "keys = list(_mua.keys())\n",
    "sampling_rate = _mua[keys[0]].attrs['sample_rate']\n",
    "units = _mua[keys[0]]['data'].attrs['unit']\n",
    "MUA = np.r_[[_mua[key]['data'].value.flatten() for key in keys]].T\n",
    "MUA = MUA[:, np.argsort(electrode_idx)]\n",
    "MUA = neo.AnalogSignal(MUA, \n",
    "                       units=units, t_stop=t_stop, sampling_rate=sampling_rate)\n",
    "MUA = MUA.rescale('mV')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSD\n",
    "coords=np.arange(LFP.shape[1]).reshape((-1,1))*25*pq.um\n",
    "h = np.ones(coords.size)*25*pq.um\n",
    "diam = 100*pq.um\n",
    "CSD = csd.estimate_csd(LFP, coords=coords, h=h, diam=diam, method='StepiCSD').rescale('uA/mm**3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MouseXY tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = exdir.File(exdir_path, 'r', plugins=[exdir.plugins.quantities])\n",
    "tracks = dict()\n",
    "for key, value in f['processing']['tracking']['trackball']['position'].items():\n",
    "    tracks[key] = value\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiketrain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_plot(ax, spiketrains, T=[0., 10.], epo=None):\n",
    "    '''\n",
    "    Arguments\n",
    "    ---------\n",
    "    ax : matplotlib.axes._subplots.AxesSubplot\n",
    "    spiketrains : list of neo.SpikeTrain objects\n",
    "    T : length 2 list/tuple of floats\n",
    "        time interval in seconds\n",
    "    epo : None or neo.Epoch object\n",
    "        show onset/offset times of stimuli\n",
    "    '''\n",
    "    yticklabels = []\n",
    "    for i, spiketrain in enumerate(spiketrains):\n",
    "        yticklabels.append('{} ({})'.format(spiketrain.name, spiketrain.description))\n",
    "        ax.plot(spiketrain, np.zeros(spiketrain.size)+i, 'C0|')\n",
    "    if epo is not None:\n",
    "        axis = ax.axis('tight')\n",
    "        ax.vlines(epo.times, axis[2], axis[3], 'g')\n",
    "        ax.vlines((epo.times+epo.durations), axis[2], axis[3], 'r')        \n",
    "    ax.set_yticks(range(len(spiketrains)))\n",
    "    ax.set_yticklabels(yticklabels)\n",
    "    ax.set_ylabel('unit id')\n",
    "    ax.set_xlim(T)\n",
    "    ax.set_xlabel('t (s)')\n",
    "    ax.set_title('spike raster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "raster_plot(ax, spiketrains, T=[30., 40.], epo=epo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interspike interval (ISI) distributions (log-linear bins)\n",
    "nrows = int(np.ceil(np.sqrt(len(spiketrains))))\n",
    "ncols = int(np.ceil(len(spiketrains) / nrows))\n",
    "fig = plt.figure()\n",
    "gs = GridSpec(nrows, ncols)\n",
    "fig.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "bins = 10**np.linspace(-3, 1, 51) # 50 log-lin bins between 1 ms and 10 s\n",
    "labels = [spiketrain.name for spiketrain in spiketrains]\n",
    "for i, (sptr, name) in enumerate(zip(spiketrains, labels)):\n",
    "    ax = fig.add_subplot(gs[i // ncols, i % ncols])\n",
    "    ax.hist(np.diff(sptr), bins=bins, color='g' if 'good' in name else None)\n",
    "    ax.semilogx()\n",
    "    ax.set_xlim(bins.min(), bins.max())\n",
    "    ax.set_title('unit {} ({})'.format(sptr.name, sptr.description))\n",
    "    if i % ncols == 0:\n",
    "        ax.set_ylabel('#')\n",
    "    if i  < len(spiketrains) - ncols:\n",
    "        ax.set_xticklabels([])\n",
    "    else:\n",
    "        ax.set_xlabel('ISI (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interspike interval (ISI) distributions (linear bins)\n",
    "nrows = int(np.ceil(np.sqrt(len(spiketrains))))\n",
    "ncols = int(np.ceil(len(spiketrains) / nrows))\n",
    "fig = plt.figure()\n",
    "gs = GridSpec(nrows, ncols)\n",
    "fig.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "bins = np.linspace(1, 50, 51) # 50 log-lin bins between 1 ms and 50 ms\n",
    "for i, (sptr, name) in enumerate(zip(spiketrains, labels)):\n",
    "    ax = fig.add_subplot(gs[i // ncols, i % ncols])\n",
    "    ax.hist(np.diff(sptr)*1E3, bins=bins, color='g' if 'good' in name else None)\n",
    "    ax.set_title('unit {} ({})'.format(sptr.name, sptr.description))\n",
    "    if i % ncols == 0:\n",
    "        ax.set_ylabel('#')\n",
    "    if i  < len(spiketrains) - ncols:\n",
    "        ax.set_xticklabels([])\n",
    "    else:\n",
    "        ax.set_xlabel('ISI (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlogram(t1, t2=None, binsize=.001, limit=.02, auto=False,\n",
    "                density=False):\n",
    "    \"\"\"Return crosscorrelogram of two spike trains.\n",
    "    Essentially, this algorithm subtracts each spike time in `t1`\n",
    "    from all of `t2` and bins the results with np.histogram, though\n",
    "    several tweaks were made for efficiency.\n",
    "    Originally authored by Chris Rodger, copied from OpenElectrophy, licenced\n",
    "    with CeCill-B. Examples and testing written by exana team.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    t1 : np.array, or neo.SpikeTrain\n",
    "        First spiketrain, raw spike times in seconds.\n",
    "    t2 : np.array, or neo.SpikeTrain\n",
    "        Second spiketrain, raw spike times in seconds.\n",
    "    binsize : float, or quantities.Quantity\n",
    "        Width of each bar in histogram in seconds.\n",
    "    limit : float, or quantities.Quantity\n",
    "        Positive and negative extent of histogram, in seconds.\n",
    "    auto : bool\n",
    "        If True, then returns autocorrelogram of `t1` and in\n",
    "        this case `t2` can be None. Default is False.\n",
    "    density : bool\n",
    "        If True, then returns the probability density function.\n",
    "    See also\n",
    "    --------\n",
    "    :func:`numpy.histogram` : The histogram function in use.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (count, bins) : tuple\n",
    "        A tuple containing the bin right edges and the\n",
    "        count/density of spikes in each bin.\n",
    "    Note\n",
    "    ----\n",
    "    `bins` are relative to `t1`. That is, if `t1` leads `t2`, then\n",
    "    `count` will peak in a positive time bin.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> t1 = np.arange(0, .5, .1)\n",
    "    >>> t2 = np.arange(0.1, .6, .1)\n",
    "    >>> limit = 1\n",
    "    >>> binsize = .1\n",
    "    >>> counts, bins = correlogram(t1=t1, t2=t2, binsize=binsize,\n",
    "    ...                            limit=limit, auto=False)\n",
    "    >>> counts\n",
    "    array([0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 4, 3, 2, 1, 0, 0, 0, 0])\n",
    "\n",
    "    The interpretation of this result is that there are 5 occurences where\n",
    "    in the bin 0 to 0.1, i.e.\n",
    "\n",
    "    # TODO fix\n",
    "    # >>> idx = np.argmax(counts)\n",
    "    # >>> '%.1f, %.1f' % (abs(bins[idx - 1]), bins[idx])\n",
    "    # '0.0, 0.1'\n",
    "\n",
    "    The correlogram algorithm is identical to, but computationally faster than\n",
    "    the histogram of differences of each timepoint, i.e.\n",
    "\n",
    "    # TODO Fix the doctest\n",
    "    # >>> diff = [t2 - t for t in t1]\n",
    "    # >>> counts2, bins = np.histogram(diff, bins=bins)\n",
    "    # >>> np.array_equal(counts2, counts)\n",
    "    # True\n",
    "    \"\"\"\n",
    "    if auto: t2 = t1\n",
    "    # For auto-CCGs, make sure we use the same exact values\n",
    "    # Otherwise numerical issues may arise when we compensate for zeros later\n",
    "\n",
    "    if not int(limit * 1e10) % int(binsize * 1e10) == 0:\n",
    "        raise ValueError(\n",
    "            'Time limit {} must be a '.format(limit) +\n",
    "            'multiple of binsize {}'.format(binsize) +\n",
    "            ' remainder = {}'.format(limit % binsize))\n",
    "    # For efficiency, `t1` should be no longer than `t2`\n",
    "    swap_args = False\n",
    "    if len(t1) > len(t2):\n",
    "        swap_args = True\n",
    "        t1, t2 = t2, t1\n",
    "\n",
    "    # Sort both arguments (this takes negligible time)\n",
    "    t1 = np.sort(t1)\n",
    "    t2 = np.sort(t2)\n",
    "\n",
    "    # Determine the bin edges for the histogram\n",
    "    # Later we will rely on the symmetry of `bins` for undoing `swap_args`\n",
    "    limit = float(limit)\n",
    "\n",
    "    # The numpy.arange method overshoots slightly the edges i.e. binsize + epsilon\n",
    "    # which leads to inclusion of spikes falling on edges.\n",
    "    bins = np.arange(-limit, limit + binsize, binsize)\n",
    "\n",
    "    # Determine the indexes into `t2` that are relevant for each spike in `t1`\n",
    "    ii2 = np.searchsorted(t2, t1 - limit)\n",
    "    jj2 = np.searchsorted(t2, t1 + limit)\n",
    "\n",
    "    # Concatenate the recentered spike times into a big array\n",
    "    # We have excluded spikes outside of the histogram range to limit\n",
    "    # memory use here.\n",
    "    big = np.concatenate([t2[i:j] - t for t, i, j in zip(t1, ii2, jj2)])\n",
    "\n",
    "    # Actually do the histogram. Note that calls to np.histogram are\n",
    "    # expensive because it does not assume sorted data.\n",
    "    count, bins = np.histogram(big, bins=bins, density=density)\n",
    "\n",
    "    if auto:\n",
    "        # Compensate for the peak at time zero that results in autocorrelations\n",
    "        # by subtracting the total number of spikes from that bin. Note\n",
    "        # possible numerical issue here because 0.0 may fall at a bin edge.\n",
    "        c_temp, bins_temp = np.histogram([0.], bins=bins)\n",
    "        bin_containing_zero = np.nonzero(c_temp)[0][0]\n",
    "        count[bin_containing_zero] = 0#-= len(t1)\n",
    "\n",
    "    # Finally compensate for the swapping of t1 and t2\n",
    "    if swap_args:\n",
    "        # Here we rely on being able to simply reverse `counts`. This is only\n",
    "        # possible because of the way `bins` was defined (bins = -bins[::-1])\n",
    "        count = count[::-1]\n",
    "\n",
    "    return count, bins[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# spike-train correlelograms\n",
    "fig = plt.figure()\n",
    "gs = GridSpec(len(spiketrains), len(spiketrains))\n",
    "for i, t1 in enumerate(spiketrains):\n",
    "    for j, t2 in enumerate(spiketrains):\n",
    "        if j < i:\n",
    "            continue\n",
    "        else:\n",
    "            bin_width = par['corr_bin_width'].rescale('s').magnitude\n",
    "            limit = par['corr_limit'].rescale('s').magnitude\n",
    "            count, bins = correlogram(t1=t1.as_array(), t2=t2.as_array(),\n",
    "                                      binsize=bin_width, limit=limit,\n",
    "                                      auto=True if i == j else False)\n",
    "            ax = fig.add_subplot(gs[i, j])\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.bar(bins, count, width=bin_width)\n",
    "            ax.set_ylim(0, count.max())\n",
    "            ax.set_xlim([-limit, limit])\n",
    "            if i == 0:\n",
    "                ax.set_title('#{}'.format(t2.name), fontsize='medium')\n",
    "            if i == j:\n",
    "                ax.set_ylabel('#{}'.format(t1.name))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# timeseries analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def some plotting functions\n",
    "def remove_axis_junk(ax, lines=['right', 'top']):\n",
    "    for loc, spine in ax.spines.items():\n",
    "        if loc in lines:\n",
    "            spine.set_color('none')            \n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "def draw_lineplot(\n",
    "        ax, data, dt=0.1,\n",
    "        T=(0, 200),\n",
    "        scaling_factor=1.,\n",
    "        vlimround=None,\n",
    "        label='local',\n",
    "        scalebar=True,\n",
    "        unit='mV',\n",
    "        ylabels=True,\n",
    "        color='k',\n",
    "        ztransform=True,\n",
    "        filter=False,\n",
    "        filterargs=dict(N=2, Wn=0.02, btype='lowpass')\n",
    "        ):\n",
    "    ''' draw some nice lines'''\n",
    "    \n",
    "    tvec = np.arange(data.shape[1])*dt\n",
    "    if T[0] < 0:\n",
    "        tvec += T[0]\n",
    "    try:\n",
    "        tinds = (tvec >= T[0]) & (tvec <= T[1])\n",
    "    except TypeError:\n",
    "        print(data.shape, T)\n",
    "        raise Exception\n",
    "    \n",
    "    # apply temporal filter\n",
    "    if filter:\n",
    "        b, a = ss.butter(**filterargs)\n",
    "        data = ss.filtfilt(b, a, data, axis=-1)\n",
    "    \n",
    "    #subtract mean in each channel\n",
    "    if ztransform:\n",
    "        dataT = data.T - data.mean(axis=1)\n",
    "        data = dataT.T\n",
    "\n",
    "    zvec = np.arange(data.shape[0])\n",
    "    vlim = abs(data[:, tinds]).max()\n",
    "    if vlimround is None:\n",
    "        vlimround = 2.**np.round(np.log2(vlim)) / scaling_factor\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    yticklabels=[]\n",
    "    yticks = []\n",
    "    \n",
    "    for i, z in enumerate(zvec):\n",
    "        if i == 0:\n",
    "            ax.plot(tvec[tinds], data[i][tinds] / vlimround + z, lw=.5,\n",
    "                    rasterized=False, label=label, clip_on=False,\n",
    "                    color=color)\n",
    "        else: \n",
    "            ax.plot(tvec[tinds], data[i][tinds] / vlimround + z, lw=.5,\n",
    "                    rasterized=False, clip_on=False,\n",
    "                    color=color)\n",
    "        yticklabels.append('ch. %i' % (i+1))\n",
    "        yticks.append(z)\n",
    "        \n",
    "    if scalebar:\n",
    "        ax.plot([tvec[tinds][-1], tvec[tinds][-1]],\n",
    "                [zvec[-1], zvec[-2]], lw=2, color='k', clip_on=False)\n",
    "        ax.text(tvec[tinds][-1]+np.diff(T)*0.0, np.mean([zvec[-1], zvec[-2]]),\n",
    "                '$2^{' + '{}'.format(int(np.log2(vlimround))) + '}$ ' + '{0}'.format(unit),\n",
    "                color='r', rotation='vertical',\n",
    "                va='center', zorder=100)\n",
    "\n",
    "    ax.axis(ax.axis('tight'))\n",
    "    ax.yaxis.set_ticks(yticks)\n",
    "    if ylabels:\n",
    "        ax.yaxis.set_ticklabels(yticklabels)\n",
    "        #ax.set_ylabel('channel', labelpad=0.1)\n",
    "    else:\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "    remove_axis_junk(ax, lines=['right', 'top'])\n",
    "    ax.set_xlabel(r'time (ms)', labelpad=0.1)\n",
    "    \n",
    "    return vlimround\n",
    "\n",
    "def draw_imageplot(\n",
    "        ax, data, dt=0.1,\n",
    "        T=(0, 200),\n",
    "        scaling_factor=1.,\n",
    "        label='local',\n",
    "        unit='mV',\n",
    "        ylabels=True,\n",
    "        vmax=None,\n",
    "        color='k',\n",
    "        colorbar=True,\n",
    "        ztransform=False,\n",
    "        filter=False,\n",
    "        filterargs=dict(N=2, Wn=0.02, btype='lowpass')):\n",
    "    ''' draw some nice images'''\n",
    "    \n",
    "    tvec = np.arange(data.shape[1])*dt\n",
    "    if T[0] < 0:\n",
    "        tvec += T[0]\n",
    "    try:\n",
    "        tinds = (tvec >= T[0]) & (tvec <= T[1])\n",
    "    except TypeError:\n",
    "        print(data.shape, T)\n",
    "        raise Exception\n",
    "    \n",
    "    # apply temporal filter\n",
    "    if filter:\n",
    "        b, a = ss.butter(**filterargs)\n",
    "        data = ss.filtfilt(b, a, data, axis=-1)\n",
    "    \n",
    "    #subtract mean in each channel\n",
    "    if ztransform:\n",
    "        dataT = data.T - data.mean(axis=1)\n",
    "        data = dataT.T\n",
    "\n",
    "    zvec = np.arange(data.shape[0])\n",
    "\n",
    "    yticklabels=[]\n",
    "    yticks = []    \n",
    "    for i, z in enumerate(zvec):\n",
    "        yticklabels.append('ch. %i' % (i+1))\n",
    "        yticks.append(z)\n",
    "\n",
    "    if vmax is None:\n",
    "        vmin = -data.std()*2.5\n",
    "        vmax = data.std()*2.5\n",
    "    else:\n",
    "        vmin = -vmax\n",
    "        \n",
    "    # plot data as image\n",
    "    im = ax.imshow(data[:, tinds], \n",
    "                   extent=(tvec[tinds][0], tvec[tinds][-1], zvec[0]-0.5, zvec[-1]+0.5), \n",
    "                   vmin=vmin, vmax=vmax, \n",
    "                   zorder=-1, cmap='bwr_r', interpolation='bilinear',\n",
    "                   origin='lower')\n",
    "\n",
    "    if colorbar:\n",
    "        rect = np.array(ax.get_position().bounds)\n",
    "        rect[0] += rect[2] + 0.01\n",
    "        rect[1] = 0.3\n",
    "        rect[2] = 0.01\n",
    "        rect[3] = 0.4\n",
    "        cax = fig.add_axes(rect)\n",
    "        cbar = plt.colorbar(im, cax=cax)\n",
    "        cbar.set_label(unit)\n",
    "\n",
    "\n",
    "    ax.axis(ax.axis('tight'))\n",
    "    ax.yaxis.set_ticks(yticks)\n",
    "    if ylabels:\n",
    "        ax.yaxis.set_ticklabels(yticklabels)\n",
    "        #ax.set_ylabel('channel', labelpad=0.1)\n",
    "    else:\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "    remove_axis_junk(ax, lines=['right', 'top'])\n",
    "    ax.set_xlabel(r'time (ms)', labelpad=0.1)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise LFP channel Pearson correlation coefficient\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax.imshow(np.corrcoef(LFP.T), vmin=-1, vmax=1)\n",
    "ax.axis(ax.axis('equal'))\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFP time series\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "draw_lineplot(ax, np.array(LFP).T, dt=1., T=(30000, 40000), unit=str(LFP.units))\n",
    "axis = ax.axis()\n",
    "ax.vlines(epo.times*1000, axis[2], axis[3], 'g')\n",
    "ax.vlines((epo.times+epo.durations)*1000, axis[2], axis[3], 'r')\n",
    "ax.set_title('LFP shank {}'.format(channel_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFP power spectra (per channel)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for x in LFP.T:\n",
    "    ax.psd(np.array(x), NFFT=NFFT, Fs=float(LFP.sampling_rate.simplified), noverlap=noverlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFP/CSD time series\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "draw_lineplot(ax, np.array(LFP).T, dt=1., T=(30000, 40000), unit=str(LFP.units))\n",
    "draw_imageplot(ax, np.array(CSD).T, dt=1., T=(30000, 40000), unit=str(CSD.units))\n",
    "axis = ax.axis()\n",
    "ax.vlines(epo.times*1000, axis[2], axis[3], 'g')\n",
    "ax.vlines((epo.times+epo.durations)*1000, axis[2], axis[3], 'r')\n",
    "ax.set_title('LFP/CSD shank {}'.format(channel_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CSD time series\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "draw_lineplot(ax, np.array(CSD).T, dt=1., T=(30000, 40000), unit=str(CSD.units))\n",
    "draw_imageplot(ax, np.array(CSD).T, dt=1., T=(30000, 40000), unit=str(CSD.units))\n",
    "axis = ax.axis()\n",
    "ax.vlines(epo.times*1000, axis[2], axis[3], 'g')\n",
    "ax.vlines((epo.times+epo.durations)*1000, axis[2], axis[3], 'r')\n",
    "ax.set_title('CSD shank {}'.format(channel_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUA time series\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "draw_lineplot(ax, np.array(MUA).T, dt=1., T=(30000, 40000), unit=str(MUA.units))\n",
    "axis = ax.axis()\n",
    "ax.vlines(epo.times*1000, axis[2], axis[3], 'g')\n",
    "ax.vlines((epo.times+epo.durations)*1000, axis[2], axis[3], 'r')\n",
    "ax.set_title('MUA shank {}'.format(channel_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MUA RMS across depth (MUA is already rectified). \n",
    "# Not identical, but inspired by Senzai et al., \n",
    "# Layer-Specific Physiological Features and Interlaminar Interactions in the \n",
    "# Primary Visual Cortex of the Mouse, Neuron (2018), https://doi.org/10.1016/j.neuron.2018.12.009\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(MUA.mean(axis=0), np.arange(MUA.shape[1]), label=r'$\\overline{\\mathrm{MUA}}$')\n",
    "ax.plot(MUA.std(axis=0), np.arange(MUA.shape[1]), label=r'$\\sigma_\\mathrm{MUA}$')\n",
    "ax.set_yticks(range(MUA.shape[1]))\n",
    "ax.legend(loc='best')\n",
    "ax.set_yticklabels(['ch. {}'.format(i+1) for i in range(MUA.shape[1])])\n",
    "ax.set_xlabel(r'$\\overline{\\mathrm{MUA}} & \\sigma_\\mathrm{MUA}$')\n",
    "ax.set_title('mean MUA across channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whitened LFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LFP with whitened (spatially decorrelated) LFP in some frequency band\n",
    "# Filter coefficients\n",
    "b, a = ss.butter(N=1, Wn=np.array([1., 50.]) / LFP.sampling_rate * 2, btype='bandpass')\n",
    "# filtered LFP\n",
    "fLFP = neo.AnalogSignal(ss.filtfilt(b, a, LFP, axis=0), units=LFP.units, sampling_rate=LFP.sampling_rate)\n",
    "# and corresponding whitening matrix\n",
    "M = np.cov(fLFP.T)\n",
    "w, E = np.linalg.eig(M)\n",
    "W = np.array(np.matrix(E)*np.matrix(np.diag(w**-0.5))*np.matrix(E).T)*LFP.shape[1]\n",
    "# compute the whitened filtered LFP\n",
    "wfLFP = np.dot(W, fLFP.T).T\n",
    "\n",
    "#fig, axes = plt.subplots(2, 1)\n",
    "#ax = axes[0]\n",
    "fig, ax = plt.subplots(1,1)\n",
    "draw_lineplot(ax, np.array(fLFP.T), dt=1., T=(30000, 40000), unit=LFP.units)\n",
    "axis = ax.axis()\n",
    "ax.vlines(epo.times*1000, axis[2], axis[3], 'g')\n",
    "ax.vlines((epo.times+epo.durations)*1000, axis[2], axis[3], 'r')\n",
    "\n",
    "#ax = axes[1]\n",
    "fig, ax = plt.subplots(1,1)\n",
    "draw_lineplot(ax, np.array(wfLFP.T), dt=1., T=(30000, 40000), unit=LFP.units)\n",
    "axis = ax.axis()\n",
    "ax.vlines(epo.times*1000, axis[2], axis[3], 'g')\n",
    "ax.vlines((epo.times+epo.durations)*1000, axis[2], axis[3], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot whitening matrix\n",
    "fig, ax = plt.subplots(1,1)\n",
    "im = ax.matshow(W)\n",
    "ax.axis(ax.axis('equal'))\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSD/LFP/MUA/wLFP of different trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = 'LFP' # or 'LFP' or 'MUA' or 'fLFP' or 'wfLFP' or 'wLFP'\n",
    "if data == 'CSD':\n",
    "    signal = CSD\n",
    "    vlimround=2**6\n",
    "elif data == 'LFP':\n",
    "    signal = LFP\n",
    "    vlimround = 2**-2\n",
    "elif data == 'fLFP':\n",
    "    signal = fLFP\n",
    "    vlimround = 2**-2\n",
    "elif data == 'MUA':\n",
    "    signal = MUA\n",
    "    vlimround = 2**-4\n",
    "elif data == 'wfLFP':\n",
    "    signal = wfLFP\n",
    "    vlimround = 2**6\n",
    "elif data == 'wLFP':\n",
    "    signal = wLFP\n",
    "    vlimround = 2**6\n",
    "\n",
    "prestim_duration = 200*pq.ms\n",
    "    \n",
    "if stimulation_type in ['image', 'grating', 'flash']:\n",
    "    labels_ = np.unique(epo.labels)\n",
    "    if labels_.size < 10:\n",
    "        pass\n",
    "    else:\n",
    "        labels_ = labels_[:10]\n",
    "    for label in labels_:\n",
    "        inds = epo.labels == label\n",
    "        container = np.zeros((int(((prestim_duration + epo.durations)*signal.sampling_rate).simplified[0]), \n",
    "                              signal.shape[1], \n",
    "                              inds.sum()))\n",
    "        for j, (time, duration) in enumerate(zip(epo.times[inds], epo.durations[inds])):\n",
    "            time_slice = signal.time_slice(time-prestim_duration, time+duration)\n",
    "            if time_slice.shape != container[:, :, j].shape:\n",
    "                container[:, :, j] = time_slice[:container.shape[0], :]\n",
    "            else:\n",
    "                container[:, :, j] = time_slice\n",
    "        # center using prestim duration\n",
    "        container = container - container[:int(prestim_duration)].mean(axis=0)       \n",
    "        \n",
    "        # colorbar range\n",
    "        vmax = container.mean(axis=-1).std()*2.5\n",
    "        \n",
    "        # find a suitable number of trials to show:\n",
    "        ncols = epo.labels.size // np.unique(epo.labels).size\n",
    "        if ncols > 8:\n",
    "            ncols = 10\n",
    "        else:\n",
    "            ncols += 2\n",
    "        \n",
    "        fig, axes = plt.subplots(ncols=ncols, nrows=1, sharey=True)\n",
    "        fig.suptitle(label)\n",
    "        for i, ax in enumerate(axes):\n",
    "            if i < (ncols - 2):\n",
    "                draw_lineplot(ax, container[:,:,i].T, \n",
    "                              dt=1., \n",
    "                              T=(-float(prestim_duration), float(duration.rescale('ms'))), \n",
    "                              vlimround=vlimround,\n",
    "                              scalebar=False,\n",
    "                              unit=str(signal.units),\n",
    "                             )\n",
    "                draw_imageplot(ax, container[:,:,i].T, \n",
    "                               dt=1., \n",
    "                               T=(-float(prestim_duration), float(duration.rescale('ms'))), \n",
    "                               unit=str(signal.units),\n",
    "                               colorbar=False,\n",
    "                               #ztransform=True,\n",
    "                               vmax=vmax\n",
    "                              )\n",
    "                ax.set_title('# {}'.format(i+1))\n",
    "            elif i == (ncols - 2): # MEAN\n",
    "                draw_lineplot(ax, container.mean(axis=-1).T, \n",
    "                              dt=1., \n",
    "                              T=(-float(prestim_duration), float(duration.rescale('ms'))), \n",
    "                              vlimround=vlimround,\n",
    "                              scalebar=False,\n",
    "                              unit=str(signal.units),\n",
    "                              )\n",
    "                draw_imageplot(ax, container.mean(axis=-1).T, \n",
    "                               dt=1., \n",
    "                               T=(-float(prestim_duration), float(duration.rescale('ms'))), \n",
    "                               unit=str(signal.units),\n",
    "                               colorbar=False,\n",
    "                               vmax=vmax\n",
    "                              )\n",
    "                ax.set_title('mean')\n",
    "            elif i == (ncols - 1): # STD\n",
    "                draw_lineplot(ax, container.std(axis=-1).T, \n",
    "                              dt=1., \n",
    "                              T=(-float(prestim_duration), float(duration.rescale('ms'))), \n",
    "                              vlimround=vlimround,\n",
    "                              unit=str(signal.units),\n",
    "                             )\n",
    "                draw_imageplot(ax, container.std(axis=-1).T, \n",
    "                               dt=1., \n",
    "                               T=(-float(prestim_duration), float(duration.rescale('ms'))), \n",
    "                               unit=str(signal.units),\n",
    "                               colorbar=True,\n",
    "                               #ztransform=True,\n",
    "                               vmax=vmax\n",
    "                              )\n",
    "                ax.set_title('std')\n",
    "            if i != 0:\n",
    "                plt.setp(ax.get_yticklabels(), visible=False)\n",
    "            #    ax.set_yticklabels([])\n",
    "            #    ax.set_ylabel('')\n",
    "            #    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare mean response to different stimuli\n",
    "if stimulation_type in ['image', 'grating', 'flash']:\n",
    "    labels_ = np.unique(epo.labels)\n",
    "    if labels_.size < 10:\n",
    "        pass\n",
    "    else:\n",
    "        labels_ = labels_[:10]\n",
    "\n",
    "    #mean_data = []\n",
    "    ncols = labels_.size\n",
    "    fig, axes = plt.subplots(ncols=ncols, nrows=1, sharey=True)\n",
    "    for i, (ax, label) in enumerate(zip(axes, labels_)):\n",
    "        inds = epo.labels == label\n",
    "        container = np.zeros((int(((prestim_duration+epo.durations)*signal.sampling_rate).simplified[0]), \n",
    "                              signal.shape[1], \n",
    "                              inds.sum()))\n",
    "        for j, (time, duration) in enumerate(zip(epo.times[inds], epo.durations[inds])):\n",
    "            time_slice = signal.time_slice(time-prestim_duration, time+duration)\n",
    "            if time_slice.shape != container[:, :, j].shape:\n",
    "                container[:, :, j] = time_slice[:container.shape[0], :]\n",
    "            else:\n",
    "                container[:, :, j] = time_slice\n",
    "        # compute mean across trials\n",
    "        container = container.mean(axis=-1).T\n",
    "        # center to prestim duration:\n",
    "        container = (container.T - container[:, :int(prestim_duration)].mean(axis=-1)).T\n",
    "        draw_lineplot(ax, container, \n",
    "                      dt=1., \n",
    "                      T=(-float(prestim_duration), float(duration.rescale('ms'))),\n",
    "                      vlimround=vlimround,\n",
    "                      scalebar=False if i < (len(labels_)-1) else True,\n",
    "                      unit=str(signal.units),\n",
    "                     )\n",
    "        draw_imageplot(ax, container, \n",
    "                       dt=1., \n",
    "                       T=(-float(prestim_duration), float(duration.rescale('ms'))), \n",
    "                       unit=str(signal.units),\n",
    "                       colorbar=False if i < (len(labels_)-1) else True,\n",
    "                       vmax=container.std()*2.5\n",
    "                      )\n",
    "        if stimulation_type == 'grating':\n",
    "            ax.set_title(label.replace(',\\\\', '$\\n$\\\\').strip(','))\n",
    "        else:\n",
    "            ax.set_title(label.split('\\\\')[-1])\n",
    "\n",
    "        if i != 0:\n",
    "            ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Alex: Store mean response per stimulus\n",
    "# compare mean response to different stimuli\n",
    "if stimulation_type in ['image', 'grating', 'flash']:\n",
    "    labels_ = np.unique(epo.labels)\n",
    "    mean_trial_data = []\n",
    "    for i, label in enumerate(labels_):\n",
    "        inds = epo.labels == label\n",
    "        container = np.zeros((int((epo.durations*signal.sampling_rate)[0]), signal.shape[1], inds.sum()))\n",
    "        for j, (time, duration) in enumerate(zip(epo.times[inds], epo.durations[inds])):\n",
    "            container[:, :, j] = signal.time_slice(time, time+duration)\n",
    "        mean_trial_data.append(container.mean(axis=-1))\n",
    "    mean_trial_data = np.array(mean_trial_data) # n_labels * n_timesamples * n_channels\n",
    "    f = h5py.File('mean_trial_data.h5', 'w')\n",
    "    f['data'] = mean_trial_data\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time, duration, signal.duration, signal, epo.times, epo.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSD PCA projection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "data = CSD[:,16:] # use one channel data as input\n",
    "x = np.zeros((epo.labels.size, int((epo.durations*data.sampling_rate)[0]*data.shape[1])))\n",
    "for i, (label, time, duration) in enumerate(zip(epo.labels, epo.times, epo.durations)):\n",
    "    x[i, ] = data.time_slice(time, time+duration).T.flatten()\n",
    "#x -= x.mean(axis=0)\n",
    "x = (x.T - x.mean(axis=1)).T\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.matshow(x, vmin=-x.std()*2.5, vmax=x.std()*2.5)\n",
    "ax.axis(ax.axis('tight'))\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.matshow(x[np.argsort(epo.labels)], vmin=-x.std()*2.5, vmax=x.std()*2.5)\n",
    "ax.axis(ax.axis('tight'))\n",
    "\n",
    "cov = np.cov(x.T)\n",
    "u, d, v = np.linalg.svd(cov)\n",
    "\n",
    "p = np.dot(x, u)\n",
    "\n",
    "C = 4\n",
    "plt.figure()\n",
    "k = 0\n",
    "for i,j in np.ndindex((C,C)):\n",
    "    k += 1    \n",
    "    if i > j: continue\n",
    "    \n",
    "    plt.subplot(C,C,k)\n",
    "    if i == j:\n",
    "        plt.hist(p[:,i])        \n",
    "    if j > i:\n",
    "        plt.plot(p[:,i], p[:,j], '.', ms=0.5)\n",
    "\n",
    "plt.figure()\n",
    "k = 0\n",
    "colors = [plt.get_cmap('tab10')(i) for i in range(np.unique(epo.labels).size)]\n",
    "for i,j in np.ndindex((C,C)):\n",
    "    k += 1    \n",
    "    if i > j: continue\n",
    "    for h, label in enumerate(np.unique(epo.labels)):\n",
    "        inds = epo.labels == label\n",
    "\n",
    "        plt.subplot(C,C,k)\n",
    "        if i == j:\n",
    "            plt.hist(p[inds,i], color=colors[h])        \n",
    "        if j > i:\n",
    "            plt.plot(p[inds, i], p[inds, j], '.', ms=0.5, color=colors[h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-unit responses to stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for spiketrain in spiketrains:\n",
    "    title = 'unit {} ({})'.format(spiketrain.name, spiketrain.description)\n",
    "\n",
    "    labels = np.unique(epo.labels)\n",
    "    ntrials = int(np.ceil(epo.labels.size / labels.size))\n",
    "    container = np.zeros((ntrials, labels.size))\n",
    "\n",
    "    # determine significance level assuming a stationary rate poisson process\n",
    "    #mean_rate = elephant.statistics.mean_firing_rate(spiketrain)\n",
    "        \n",
    "    for j, label in enumerate(labels):\n",
    "        inds = epo.labels == label\n",
    "        for i, (time, duration) in enumerate(zip(epo.times[inds], epo.durations[inds])):\n",
    "            container[i, j] += spiketrain.time_slice(time, time+duration).size\n",
    "    fig, axes = plt.subplots(3, 1, sharex=True)\n",
    "    fig.subplots_adjust(bottom=0.3)\n",
    "    ax = axes[0]\n",
    "    im = ax.pcolormesh(np.arange(labels.size+1)-0.5, np.arange(ntrials+1)-0.5, container, \n",
    "                       vmin=0, vmax=50, cmap='gray_r')\n",
    "    ax.axis(ax.axis('tight'))\n",
    "    ax.set_xticks(np.arange(labels.size))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_ylabel('trial #')\n",
    "    ax.set_title(title)\n",
    "    # total spike count\n",
    "    ax = axes[1]\n",
    "    ax.bar(np.arange(labels.size), container.sum(axis=0))\n",
    "    ax.set_ylabel('tot. spike count')\n",
    "    ax.axis(ax.axis('tight'))\n",
    "    # rate per stim\n",
    "    ax = axes[2]\n",
    "    ax.bar(np.arange(labels.size), (container.sum(axis=0) / epo.durations.sum()*labels.size).simplified)\n",
    "    mean_rate = (container.sum() / epo.durations.sum()).simplified    \n",
    "    ax.hlines(mean_rate, -1, len(labels), linestyle=':')\n",
    "    ax.set_ylabel('rate (1/s)')\n",
    "    ax.set_xticks(np.arange(labels.size))\n",
    "    ax.set_xticklabels(labels, rotation=90, fontsize='x-small')\n",
    "    ax.axis(ax.axis('tight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tuning curves\n",
    "if stimulation_type == 'grating':\n",
    "    for spiketrain in spiketrains:\n",
    "        title = 'unit {} ({})'.format(spiketrain.name, spiketrain.description)\n",
    "        labels = np.unique(epo.annotations['orientation'])\n",
    "        ntrials = int(np.ceil(epo.labels.size / labels.size))\n",
    "        container = np.zeros((ntrials, labels.size))\n",
    "\n",
    "        for j, label in enumerate(labels):\n",
    "            inds = epo.annotations['orientation'] == label\n",
    "            for i, (time, duration) in enumerate(zip(epo.times[inds], epo.durations[inds])):\n",
    "                container[i, j] += spiketrain.time_slice(time, time+duration).size\n",
    "        # determine significance level assuming a stationary rate poisson process\n",
    "        # mean_rate = elephant.statistics.mean_firing_rate(spiketrain)\n",
    "\n",
    "        fig, axes = plt.subplots(3, 1, sharex=True)\n",
    "        fig.subplots_adjust(bottom=0.2)\n",
    "        ax = axes[0]\n",
    "        im = ax.pcolormesh(np.arange(labels.size+1)-0.5, np.arange(ntrials+1)-0.5, \n",
    "                           container, vmin=0, vmax=20, cmap='gray_r')\n",
    "        ax.axis(ax.axis('tight'))\n",
    "        ax.set_xticks(np.arange(labels.size))\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_ylabel('trial #')\n",
    "        ax.set_title(title)\n",
    "        ax = axes[1]\n",
    "        ax.bar(np.arange(labels.size), container.sum(axis=0))\n",
    "        #ax.hlines(mean_rate.magnitude, -1, len(labels), linestyle=':')\n",
    "        ax.set_xticks(np.arange(labels.size))\n",
    "        ax.set_xticklabels([str(label).split('\\\\')[-1] for label in labels], rotation=90, fontsize=12)\n",
    "        ax.set_ylabel('tot. spike count')\n",
    "        # rate per stim\n",
    "        ax = axes[2]\n",
    "        ax.bar(np.arange(labels.size), (container.sum(axis=0) / epo.durations.sum()*len(labels)).simplified)\n",
    "        mean_rate = (container.sum() / epo.durations.sum()).simplified  \n",
    "        ax.hlines(mean_rate.magnitude, -1, len(labels), linestyle=':')\n",
    "        ax.set_ylabel('rate (1/s)')\n",
    "        ax.set_xticks(np.arange(labels.size))\n",
    "        ax.set_xticklabels(labels, rotation=90, fontsize='x-small')\n",
    "        ax.axis(ax.axis('tight'))\n",
    "        \n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate image sequence with binned spike trains\n",
    "if stimulation_type in ['sparsenoise']:\n",
    "    # load h5 file with image data\n",
    "    im_path = os.path.join(expipe_temp_storage, project_id, \n",
    "                          'COBRA_PsychoPy_files', 'files', 'datasets', \n",
    "                          'sparse_noise_images', 'imageData.h5')\n",
    "    f = h5py.File(im_path, 'r')\n",
    "    im_data = f['data'][:, :epo.size]\n",
    "    im_dimensions = f['dimensions'].value\n",
    "    f.close()\n",
    "    im_shape = im_data.shape\n",
    "    im_data = im_data.reshape((-1), im_data.shape[-1])\n",
    "    \n",
    "    for spiketrain in spiketrains:\n",
    "        title = 'unit {}'.format(spiketrain.name)\n",
    "        # count spike events per image\n",
    "        sptr_binned = np.zeros(im_data.shape[-1], dtype=int)\n",
    "        for i, (time, duration) in enumerate(zip(epo.times, epo.durations)):\n",
    "            sptr_binned[i] += spiketrain.time_slice(time, time+duration).size\n",
    "        corr = np.corrcoef(np.row_stack([sptr_binned, im_data]))[1:, 0].reshape(im_shape[:2])\n",
    "        plt.figure()\n",
    "        plt.imshow(corr, cmap='gray', vmin=-corr.std()*2, vmax=corr.std()*2, interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlate image sequence with binned spike trains\n",
    "if stimulation_type in ['image']:\n",
    "    # load h5 file with image data\n",
    "    im_path = os.path.join(os.environ['HOME'], 'COBRA', \n",
    "                          'COBRA_PsychoPy_files', 'files', 'datasets', \n",
    "                          'converted_images', 'imageData.h5')\n",
    "\n",
    "    f = h5py.File(im_path, 'r')\n",
    "    im_data = f['data'].value\n",
    "    im_dimensions = f['dimensions'].value\n",
    "    f.close()\n",
    "    im_shape = im_data.shape\n",
    "    \n",
    "    # test that downsampling works\n",
    "    plt.matshow(im_data[:, :, 0], cmap='gray')\n",
    "    plt.title('original')\n",
    "    \n",
    "    \n",
    "    # downsample image (too high-res for correlation calc)\n",
    "    im_data = block_reduce(im_data, block_size=(10, 10, 1), func=np.mean)\n",
    "    plt.matshow(im_data[:, :, 0], cmap='gray')\n",
    "    plt.title('downsampled')\n",
    "    im_shape = im_data.shape\n",
    "    im_data = im_data.reshape((-1), im_data.shape[-1])\n",
    "    \n",
    "    # epoch bins\n",
    "    bins = np.r_[epo.times, [epo.times[-1]+epo.durations[-1]]]\n",
    "    for spiketrain in spiketrains:\n",
    "        title = 'unit {} ({})'.format(spiketrain.name, spiketrain.description)\n",
    "        # count spike events per image showing\n",
    "        sptr_binned_tmp, _ = np.histogram(spiketrain.times, bins=bins)\n",
    "        sptr_binned = np.zeros(im_shape[-1], dtype=int)\n",
    "        # collapse bins with the same image\n",
    "        for i, label in enumerate(np.unique(epo.labels)):\n",
    "            inds = epo.labels == label\n",
    "            sptr_binned[i] = sptr_binned_tmp[inds].sum()\n",
    "        corr = np.corrcoef(np.row_stack([sptr_binned, im_data]))[1:, 0].reshape(im_shape[:2])\n",
    "        plt.figure()\n",
    "        plt.imshow(corr, cmap='gray', vmin=-corr.std()*2, vmax=corr.std()*2, interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate movie data with binned spike trains\n",
    "if stimulation_type in ['movie']:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSTH\n",
    "(peristimulus time histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psth(st, epoch, fig=None, axes=None, lags=(-0.1*pq.s, 1*pq.s), bin_size=0.01*pq.s, \n",
    "              marker='|', color='C0', n_trials=10,  histtype='bar'):\n",
    "    '''\n",
    "    Parameters:\n",
    "    st : neo.SpikeTrain\n",
    "    epoch : neo.Epoch\n",
    "    lags : tuple of Quantity scalars\n",
    "    bin_size : Quantity scalar\n",
    "    color : mpl color \n",
    "    n_trials : int\n",
    "        number of trials to include in PSTH\n",
    "    '''\n",
    "    labels = np.unique(epoch.labels, axis=-1)\n",
    "    bins = np.linspace(lags[0], lags[1], int((lags[1]-lags[0])//bin_size)+1)\n",
    "    \n",
    "    if fig is None:\n",
    "        fig, axes = plt.subplots(2, len(labels), sharex=True, sharey='row')\n",
    "        fig.suptitle('unit {} ({})'.format(st.name, st.description))\n",
    "    for i, label in enumerate(labels):\n",
    "        axes[0, i].set_xlim(lags)\n",
    "        axes[1, i].set_xlim(lags)\n",
    "\n",
    "        sts = []\n",
    "        for h, epo in enumerate(epoch[epoch.labels == label]):\n",
    "            if h < n_trials:\n",
    "                st_ = st.time_slice(t_start=(epo+lags[0]).simplified, \n",
    "                                    t_stop=(epo+lags[1]).simplified)\n",
    "                sts.append((st_.times.simplified - epo.simplified).tolist())\n",
    "                axes[0, i].plot(sts[h], np.zeros(len(sts[h])) + h, marker, color=color)\n",
    "\n",
    "        axes[0, i].set_title('{}'.format(label), fontsize='x-small')\n",
    "        axes[1, i].set_xlabel('lag (s)')\n",
    "        axes[1, i].hist(flattenlist(sts), bins=bins, color=color, histtype=histtype)\n",
    "        if i == 0:\n",
    "            axes[0, i].set_ylabel('trial #')\n",
    "            axes[1, i].set_ylabel('#')\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stimulation_type in ['image', 'flash']:\n",
    "    for st in spiketrains:\n",
    "        plot_psth(st, epo, lags=(-0.1*pq.s, epo.durations[0]), n_trials=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USB mouse recordings (trackball data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "for key, value in tracks.items():\n",
    "    ax.plot(value['times'].value, value['data'].value.cumsum(), label=key)\n",
    "ax.legend(loc='best')\n",
    "ax.set_title('USB-mice paths')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_ylabel('displacement (a.u.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
